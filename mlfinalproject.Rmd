---
title: "Predicting the Quality of Weigth Lifting Exerice Using Random Forest"
author: "Nilrey Jim Cornites"
date: "November 19, 2017"
output: 
        html_document: default
        pdf_document: default
  
---

```{r setup, include=FALSE, cache=TRUE}
knitr::opts_chunk$set(echo = TRUE)
setwd("D:/Stat and Data Science References/datasciencecoursera/08_Practical Machine Learning/practicalMLfinalproject")
```

## Executive Summary
This the a final project to Practical Machine Learning Class in coursera.com, 1 of the 9 courses under the Data Science Specialization.

The common problem in research is to quantify how much of a particular activity they do, but rarely to quantify how well they do it. In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict how well they do weight lifting exercise.

Using **random forest** technique, the model predicted the quality of the weighlifting with 99% accuracy `99%` or estimated `1%` out of sample error only using 52 predictors. Top 5 most important predictors are 'roll_belt', 'yaw_belt', 'pitch_forearm', 'pitch_belt' and magnet_dumbbell_z. .


## Introduction
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. See http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har for more details about the data.

## The Data

This project utilized the **Weight Lifting Exercises Dataset** from http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har. The goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

The 6 young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


## Loading Data and Some Exploratory Analyses

Following code will call Caret package which will be used to build the model, ggplot2 for visualization, and download the training and test set.
``` {r}
library(caret)
library(ggplot2)

#download the data
Url1 <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
Url2 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(Url1, destfile=trainFile)
}
if (!file.exists(testFile)) {
  download.file(Url2, destfile=testFile)
}

#load the data
training <- read.csv("./data/pml-training.csv",header=T,sep=",",na.strings=c(""," ","NA"))
testing <- read.csv("./data/pml-testing.csv",header=T,sep=",",na.strings=c(""," ","NA"))

```

### Exploratory Analyses

``` {r}

library(Amelia)
dim(training) ; dim(testing) ## succedding exploration will use only training set to avoid bias on tuning the selected model

```
We see that there are 19,622 rows and 160 columns in the training set while only 20 rows with the same number of fields in testing set. The "classe" variable in the both sets is the outcome to predict.

``` {r echo=FALSE}
str(training)

```
We can see that of 160 columns, there are many variables with lots of missing values (`NA`). We might also want to check for variables(except the outcome variable) if there's any that has variance near zero

### Data Preprocessing
We will check those those variable that has near zero variance and remove those predictors. We will also remove those predictor with missing value. We will put back those removed variables with imputed values if the prediction model looks bad.

```{r}
nzvariance<-nearZeroVar(training, saveMetrics = T)
toremove<-nzvariance[nzvariance[,"nzv"],]

print(toremove)

nrow(toremove) ## number of removed predictor

training <- training[,!nzvariance$nzv]
testing <- testing[,!nzvariance$nzv]

```

There are now `159-toremove` remaining predictor variables. The graph shows below the remainind predictor with missing value which will be removed.

```{r}
library(Amelia)
missmap(training)

# Remove variables with missing values

nomissing<-colSums(is.na(training)) == 0

training_filter_na <- training[,nomissing]
testing_filter_na <- testing[,nomissing]

# Remove unnecessary columns
colRm_train <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","num_window")
colRm_test <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","num_window","problem_id")
newtraining <- training_filter_na[,!(names(training_filter_na) %in% colRm_train)]
newtesting <- testing_filter_na[,!(names(testing_filter_na) %in% colRm_test)]
dim(newtraining)
dim(newtesting)

```

Code below will further split the training set to two subset, training set and validation set.

``` {r}
set.seed(526)
inTrain <- createDataPartition(y=newtraining$classe, p=0.7, list=FALSE)
training_clean <- newtraining[inTrain,]
validation_clean <- newtraining[-inTrain,]
```


## Model Building

Since outcome variable is categorical, We will consider Linear Discriminant Analysis (LDA) and random forest (RF) and see if later model accuracy is more supreme. 

Caveat: LDA has strict assumptions to follow that are the same to linear regression model e.g. no outliers and normality of data. One may use logistic regression (or multinomial logistics in this case since outcome variable has more than 2 category) but we will just use LDA just to have comparison with RF, as in most cases RF tend to have better performance than linear modeling approach.

``` {r}
set.seed(123)



# Fit LDA model
ldaFit <- train(classe ~ ., method = "lda", data = training_clean, importance = T, trControl = trainControl(method = "cv", number = 4))

lda_validation_pred <- predict(ldaFit, newdata=validation_clean)

```


Below will model data based on random forest algorithm.
``` {r}
set.seed(123)
# Fit rf model
rfFit <- train(classe ~ ., method = "rf", data = training_clean, importance = T, trControl = trainControl(method = "cv", number = 4))

rf_validation_pred <- predict(rfFit, newdata=validation_clean)

```

## Model Evaluation

We see that random forest model has way better accuracy. The estimated out sample error is about 1% compared to LDA which have is about 30% error rate.

``` {r}
# Check model performance
confusionMatrix(lda_validation_pred,validation_clean$classe)
confusionMatrix(rf_validation_pred,validation_clean$classe)

imp <- varImp(rfFit)$importance
varImpPlot(rfFit$finalModel, sort = TRUE, type = 1, pch = 19, col = 1, cex = 1, main = "Importance of the Predictors")

```

In the figure above, top 5 most important variables are: 'roll_belt', 'yaw_belt', 'pitch_forearm', 'pitch_belt' and magnet_dumbbell_z.

We will now use the random forest model to predict the testing set.

``` {r}
testing_pred <- predict(rfFit, newdata=newtesting)
testing_pred

```

## Conclusion
Using random forest model, we can predict how well an individual does in weigth lifting activities using the 52 predictors, with estimated out sample error of only 1%.